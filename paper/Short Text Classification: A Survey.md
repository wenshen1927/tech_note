# Short Text Classification: A Survey

***
Ge Song, Yunming Ye, Xiaolin Du, Xiaohui Huang, and Shifu Bie<br>
Shenzhen Key Laboratory of Internet Information Collaboration, Shenzhen Graduate Scho
***
2014年的哈工大深圳研究生院的一篇survey，50次引用。<br>
主要介绍了常用的方法：有监督（LSA,pLSA，LDA），半监督，集成学习，大规模在线学习和短文本分类的评价方法。
***
## 1、简介
介绍短文本类型、短文本与长文本相比具有的特点及面对的挑战、短文本出现了一些新的文本分类的方法。
1. 第二部分介绍短文本的特点和短文本遇到的困难，并介绍文本分类要做的处理；
2. 第三部分介绍基于语义分析的短文本分类；
3. 第四部分介绍半监督学习的短文本分类；
4. 第五部分介绍短文本分类的集成学习方法；
5. 第六部分介绍在线短文本分类；
6. 第七部分介绍了评估手段；
7. 第八部分总结短文本分类方法。

## 2、背景
### PART A ：短文本特性
1. 短文本定义：
定义短文本子词数不超过**200**.
2. 短文本特性：
+ **稀疏性**：很难抽取有效的文本特征；
+ **即时性**：导致短文本数量很大；
+ **非标准性**：可能会遇到一些拼写错误，或者不准确的词语和噪声；
+ **噪声和不平衡分布**：有的应用需要处理大量的文本数据，但是我们关注的仅仅是少部分目标，因而可用的文本实例很有限；
+ **大规模数据和标签瓶颈**：面对大规模数据，肯定不能手动标注，因此，如何利用有限的标注数据就成为了一个难题；
+ **传统的文本分类方法**（SVM,Bayes,KNN）等都是基于词频的相似度来计算的，由于短文本特征的稀疏性，这在短文本中肯定不行。

### PART B ：短文本分类
由于短文本的特点和存在的困难，传统的方法如kNN、朴素贝叶斯、SVM、最大熵模型等并不适合短文本分类。因此，如何合理地选择特征、高效地降低稀疏的维度和噪声、提高分类的准确率成为了短文本分类的重要问题。

## 3、基于语义分析的短文本分类

1. 目前，降低特征稀疏维度的主要方法是基于语义分析和语义特征的放阿飞。这是因为在处理文本分类问题时主要使用向量空间模型（VSM），而这个模型的前提假设是单词之间相互独立，忽略了词语之间的相关性。然而，短文本包含的语义容量较小，需要利用这种词语之间的相关性。传统的文本分类无法区分语义之间的模糊性，比如近义词和同义词，而这类词在短文本中大量出现。因此，传统的分类方法不能很好地适用于短文本分类。
2. 语义分析关注的是文本存在的概念、文本内部的语义结构以及文本之间存在的逻辑相关性。在已有的方法中，LSA(隐语义分析)具有重要的位置。利用统计学的方法，LSA能够抽取潜在的语义结构、消除同义词的影响并降低特征维度和噪音。因此，很多针对短文本分类的方法都是基于LSA做的。<br>
Zelikovitz [3]将它应用到短文本分类。Qiang Pu etc [5] 结合LSA和ICA（独立成分分析）。Xuan - Hieu Phan etc. [7] 建立了一个大规模短文本分类的框架。这个框架主要基于最近很成功的隐语义分析模型（pLSA、LDA）和强大的机器学习方法如最大熵模型和SVM。Bing-kun WANG etc. [9]提出基于LDA模型和信息增益（IG）模型来建立一个强大的特征主题词表（SFT）的方法来解决短文本分类问题。[10]在挖掘句法和语义信息的过程中，语言独立性分析（LIS）核方法被提出，来增强语言独立性。它能够有效的计算短文本的相似度，而不用语法标签信息和词汇数据库。 Mengen Chen etc.[11]提出基于多粒度主题抽取的方法，能够更加精确地抽取为短文本建模。 Transductive LSA [3] [4]（直推式LSA）是另一种基于LSA的短文本分类方法。(*后面还有一点，主要介绍这个方法，不写了*)

#### <em>A：利用LSA的短文本分类</em>
简单介绍了一下LSA的优点：它将向量空间转化为语义空间；它能够抽取语义结构、消除词语之间的相关性；能够把高维矩阵降低为低维矩阵，进而更有效地表达词语和文档之间的关系。主要使用的方法是SVD。<br>
具体做法：通过对大量的文本集进行统计分析，从中提取出词语的上下文使用含义。技术上通过SVD分解等处理，消除了同义词、多义词的影响，提高了后续处理的精度。
流程：
1. 分析文档集合，建立词汇-文本矩阵。可能是基于BOW模型构建基于频率或者TF-IDF的矩阵。
2. 对词汇-文本矩阵进行奇异值分解。
3. 对SVD分解后的矩阵进行降维。
4. 使用降维后的矩阵构建潜在语义空间。


又介绍LSA的优点：
1. 降低特征维度并减少噪音影响。能够解决大规模短文本问题。
2. 增强了语义关系。它能描述词语和文档的关系；能够减少同义词，近义词的影响。
3. 灵活。

也有缺点：
1. 在降低维度的过程中，丢失了文本的结构性信息。
2. SVD计算慢。
3. 文档只是向量的线性累加，没有考虑单词在短语中的语法信息。
4. LSA只能处理看得见的变量，不能处理隐变量。
#### <em>B：利用pLSA的短文本分类</em>
pLSA是在词（word）和文档(document)之间加入隐含主题（latent topics）这一隐变量，建立了一个概率模型，具体计算过程中要计算两个似然概率，用的是EM算法。具体过程不写了。<br>
优点：
1. pLSA有更好的估计效果。
2. 在pLSA中，每个变量的分布是明确定义的。
3. pLSA能够利用已有的统计学方法来确定最优的维度。LSA需要用一些启发式算法，计算量明显更大。

缺点：
1. pLSA需要通过训练集的计算来获得标签的先验分布，而对于测试集来说嫩姨获得标签的先验分布（没看懂。。。）
2. 随着训练数据的增加，pLSA的参数空间也会增加，这回导致过拟合。并且，抽取出来的不相关的特征只对训练集有效，对测试集可能不够有效。

#### <em>C：利用LDA的短文本分类</em>
LDA是一种生成模型，它对输入变量构建了一个判别函数。它寻求类别间的最大分离和类别内的最小差异。<br>
具体算法就不详述了。<br>
相比于LSA和pLSA,LDA能够发现测试预料中主题或者概念这类隐藏的结构。<br>
优点:LDA对实际的语义有更好的表达能力。并且他继承了pLSA的所有优点。

## 4、半监督短文本分类
半监督学习是共同利用有标签数据和无标签数据来学习。标注标签是一个费时费力的活，所以半监督学习大方法很有使用价值。
（介绍了三种方法，但是不关注）
## 5、集成短文本分类
如果短文本特征稀疏的话，那就很难计算短文本的相似性，因此单个分类器很难分类准确，。集成学习方法，通过对每个弱分类器分配不同的权重，来获取每个特征的权重，这对短文本分类问题比较适用。<br>
引用[1]提出一种针对短文本的动态集成分类算法，来解决短文本特征稀疏和类别不平衡的问题。这个方法构建了一个树形集成分类器，并提出了一种自适应策略来调整结合的结构。Aixin Sun[32]提出一种用很少单词的分类方法。它的预测策略主要是对搜索到的结果进行投票。<br>
[33]一种新的方法提出直接计算文本数据和领域的关系，而不是把单词映射为权重向量。它首先通过长文本建立领域词表；然后计算文档和领域词表的关系；如果关系值大于阈值，则
文档就被分类为这一领域。[34]提出通过抽取用户信息和用户文本信息来建立一个小的领域词表，来解决词语不够充足的问题。效果不错。
简单总结：1、集成方法的创新；2、权重更新方法的创新；3、加入领域知识，构建外部语料库；4、为短文本加入特定的领域特征。
## 6、大规模短文本实时分类
目前，相较于几个经典的分类算法，经常选择贝叶斯方法进行在线分类。
## 7、短文本分类评价
常用的评价方法包括：
Accuracy,
Precision and recall
F-measure.
Macro average and micro average
（就不展开了）
## 8、总结
目前、短文本分类主要有以下几个方面：
1. 利用语义信息降低特征维度并抽取特征；
2. 结合大量的无标签数据，利用半监督学习算法解决标签瓶颈问题；
3. 利用集成学习的方法提高分类准确率；
4. 结合线上线下学习方法解决大规模短文本分类问题。

然而，短文本分类依然是很有挑战性的问题，很多技术都在初始摸索阶段，比如在动态短文本流分类问题上还没有比较好的解决办法。由短文本分类问题引申出很多应用，比如多标签短文本分类，评论情绪分类，和话题追踪和控制等问题。
